# drug-activity-prediction

# The given dataset has the class labels as the first number in the rows in binary format 0 or 1. The features are represented in binary format as well, the rest of the numbers in a row represent the indices of the 1s in each record, and the indices represent the active compounds. I divided the class labels and indices into train Y and train X. The indices need to be mapped as 1 in each record in the corresponding index, in a compressed sparse row matrix for memory and speed optimization purposes. I created a class called “MatrixParser” to have two methods - The first method is called “calculateMatrixColumn”, this method will find out the max index in the records in the dataset and return the max index; the second method “parseIndexToMatrix” will take the returned value from the first method, and create an array of the max index length with only 0s for each data record and assign the indices that exist in each data record to 1 in the corresponding indices in the array. The parsed array for each data record will be appended to a “res” array and the “res” array will be transformed into a compressed sparse row matrix. Checking the sparse matrix for “res” of train X, we can see only the active compound, 1, in rows and columns. The same operation is applied to the test set.
Looking at the train X matrix and the characteristics of the dataset, the values are already normalized since they are already in binary format and they are not on different scales. However, some values can be dependent on others and redundancy can be eliminated to reduce the noise and dimensionality of the dataset for better accuracy. For my experiments with three types of classifiers, I applied “SelectKBest” with the chi2 score function or mutual information classification score function for feature selection [1]-[3]. With the chi2 test, the irrelevant features can be eliminated and I can choose k numbers of the top most relevant features, this is valid for this dataset because the features are non-negative. With mutual information classification, I can select the k numbers of the top most relevant features to the class label, this is valid for this dataset because the class label is discrete. For some experiments, I applied either chi2 SelectKBest or/and mutual information classification SelectKBest with different experimental k values to experiment with model accuracies based on F1 scores from cross- validation and from the validation set. The interpretations for experiments can be found in the last column of the tables.
I divided train X to train X, Y, and validation X, Y. The reason is that I want to have a validation set to validate the model performance. Before dividing, train X and Y are shuffled to keep the randomness of the train set and validation set so that our model is not constantly learning the same data which could lead to overfitting. By comparing the cross-validation F1 score and validation set F1 score, I can actually see how the model performs on unseen data.
The dataset is very imbalanced as stated in the homework description and the graph drawn below. The blue represents train Y and the orange represents validation Y. From this graph, the difference between the total counts of labels 1 and 0 is really obviously significant. This is why we need to apply resampling.
I chose to apply random oversampling [4] to over-sample the underrepresented label in the train set. The reason is that the dataset is already small, it is helpful for model training and accuracy with more data, so we over-sample instead of under-sample. The new train, validation, and test ratio is roughly 72, 7, 21. See the
 
screenshot below. Each experiment has slightly different values of train and validation class label amounts, details can be found in the screenshots column in the tables.
For cross-validation, I chose to use stratified k-fold cross-validation [5]. The reason is each fold can have equal instances of target class to prevent bias. For the Naive Bayes classifier, I choose to use Bernoulli Naive Bayes [6] because the dataset has discrete binary features and labels, for the same reason, Perceptron [7], [8] is chosen for the Neural Network classifier.
The random_state parameter is different for each experiment for reproducibility. The parameter is applied in the shuffle of train X and Y, train validation split, random oversampling, stratified k fold, decision tree classifier, and perceptron. The highlighted column is the final submission in Miner.
